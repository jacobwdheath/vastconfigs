{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import keras.utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "\n",
    "from TinyDataset import TinyImageDataset\n",
    "from StegModels import CNNModels\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "\n",
    "def pickle_file(path, filename, data):\n",
    "    with open(path + filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "train_path = os.path.join(\"datasets/tiny-imagenet-200/\", \"train\")\n",
    "\n",
    "with tf.device('gpu:0'):\n",
    "    def rev_loss(s_true, s_pred):\n",
    "        return beta * K.sum(K.square(s_true - s_pred))\n",
    "\n",
    "\n",
    "    def cover_loss(c_true, c_pred):\n",
    "        return K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "\n",
    "    def full_loss(y_true, y_pred):\n",
    "        # 1 Secret\n",
    "        s_true, c_true = y_true[..., 0:3], y_true[..., 3:6]\n",
    "        s_pred, c_pred = y_pred[..., 0:3], y_pred[..., 3:6]\n",
    "\n",
    "        s_loss = rev_loss(s_true, s_pred)\n",
    "        c_loss = K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "        return sum([s_loss, c_loss])\n",
    "\n",
    "\n",
    "    def process(_batch_size, _epochs, save_path, save_interval, activation, filter1, filter2, filter3, verbose,\n",
    "                _sec1_input, _cov_input):\n",
    "\n",
    "        cnn_model = CNNModels()\n",
    "        input_shape = _sec1_input.shape[1:]\n",
    "\n",
    "        start_time = time.time()\n",
    "        _encoder_model, _decoder_model, _autoencoder_model = cnn_model.train_one_secret_65_filters(\n",
    "            batch_size=_batch_size,\n",
    "            epochs=_epochs,\n",
    "            path=save_path,\n",
    "            shape=input_shape,\n",
    "            rev_loss=rev_loss,\n",
    "            full_loss=full_loss,\n",
    "            secret_input=_sec1_input,\n",
    "            cover_input=_cov_input,\n",
    "            verbose=verbose,\n",
    "            save_interval=save_interval,\n",
    "            activation=activation,\n",
    "            filter1=filter1,\n",
    "            filter2=filter2,\n",
    "            filter3=filter3\n",
    "        )\n",
    "        end_time = round(time.time() - start_time)\n",
    "\n",
    "        if end_time > 60:\n",
    "            end_time = end_time / 60\n",
    "            print(f\"Model Finished Training in: {end_time} m\")\n",
    "        else:\n",
    "            print(f\"Model Finished Training in: {end_time} s\")\n",
    "\n",
    "        return _encoder_model, _decoder_model, _autoencoder_model\n",
    "\n",
    "\n",
    "    def train_model(epochs, activation_function, batch_size, filters, _beta):\n",
    "        total_filters = sum(list(filters))\n",
    "        f1 = filters[0]\n",
    "        f2 = filters[1]\n",
    "        f3 = filters[2]\n",
    "\n",
    "        save_path = f\"model-data/{total_filters}F_{batch_size}BS_{epochs}EP_{activation_function}_BETA{_beta}/\"\n",
    "        dataset_local = TinyImageDataset(path=train_path, num_classes=25, normalize=True)\n",
    "        X_train_local = dataset_local.load_data()\n",
    "        sec1_input_local = X_train_local[0:2500]\n",
    "        cov_input_local = X_train_local[2500:5000]\n",
    "\n",
    "        encoder_model, decoder_model, autoencoder_model = process(\n",
    "            _batch_size=batch_size,\n",
    "            _epochs=epochs,\n",
    "            save_path=save_path,\n",
    "            save_interval=1,\n",
    "            activation=activation_function,\n",
    "            filter1=f1,\n",
    "            filter2=f2,\n",
    "            filter3=f3,\n",
    "            verbose=1,\n",
    "            _sec1_input=sec1_input_local,\n",
    "            _cov_input=cov_input_local\n",
    "        )\n",
    "\n",
    "        print(f\"Model Saved at: {save_path}\")\n",
    "\n",
    "        def run_loss_history():\n",
    "            with open(save_path + \"loss_history.pckl\", \"rb\") as f:\n",
    "                loss_history = pickle.load(f)\n",
    "\n",
    "            plt.plot(loss_history)\n",
    "            plt.title(f'Loss Curve For: 1X: {total_filters}F_{batch_size}BS_{epochs}EP_{activation_function}_{_beta}')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "\n",
    "            epoch_patch = mpatches.Patch(color='blue', label=f'Total Epochs: {epochs}')\n",
    "            beta_patch = mpatches.Patch(color='blue', label=f'Total Epochs: {_beta}')\n",
    "            batch_patch = mpatches.Patch(color='blue', label=f'Batch Size: {batch_size}')\n",
    "            act_patch = mpatches.Patch(color='blue', label=f'Activation Function: {activation_function}')\n",
    "            plt.legend(handles=[beta_patch, epoch_patch, batch_patch, act_patch], loc=\"upper right\")\n",
    "\n",
    "            plt.savefig(f\"{save_path}loss.png\")\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "\n",
    "        run_loss_history()\n",
    "\n",
    "        decoded = autoencoder_model.predict([sec1_input_local, cov_input_local])\n",
    "        decoded_S1, decoded_C = decoded[..., 0:3], decoded[..., 3:6]\n",
    "\n",
    "        def pixel_errors(input_S1, input_C, decoded_S1, decoded_C):\n",
    "            see_S1pixel = np.sqrt(np.mean(np.square(255 * (input_S1 - decoded_S1))))\n",
    "            see_Cpixel = np.sqrt(np.mean(np.square(255 * (input_C - decoded_C))))\n",
    "            return see_S1pixel, see_Cpixel\n",
    "\n",
    "        S1_error, C_error = pixel_errors(sec1_input_local, cov_input_local, decoded_S1, decoded_C)\n",
    "        diff_S1, diff_C = np.abs(decoded_S1 - sec1_input_local), np.abs(decoded_C - cov_input_local)\n",
    "\n",
    "        def show_image_results():\n",
    "            num_imgs = 4\n",
    "            random_index = [random.randint(0, 375) for _ in range(num_imgs)]\n",
    "            plt.figure(figsize=(11, 12))\n",
    "\n",
    "            def show_image(img, n_rows, num_col, index, first_row=False, title=None):\n",
    "                ax = plt.subplot(n_rows, num_col, index)\n",
    "                plt.imshow(img)\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "                if first_row:\n",
    "                    plt.title(title)\n",
    "\n",
    "            for i, idx in enumerate(random_index):\n",
    "                n_col = 8\n",
    "\n",
    "                show_image(cov_input_local[idx], num_imgs, n_col, i * n_col + 1, first_row=i == 0, title='Cover')\n",
    "\n",
    "                show_image(sec1_input_local[idx], num_imgs, n_col, i * n_col + 2, first_row=i == 0, title='Secret1')\n",
    "\n",
    "                show_image(decoded_C[idx], num_imgs, n_col, i * n_col + 5, first_row=i == 0, title='Cover*')\n",
    "\n",
    "                show_image(decoded_S1[idx], num_imgs, n_col, i * n_col + 6, first_row=i == 0, title='Decoded1')\n",
    "\n",
    "            plt.savefig(f\"{save_path}image_comparison.png\")\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "\n",
    "        show_image_results()\n",
    "\n",
    "        pickle_file(save_path, \"decoded_secret1.pckl\", decoded_S1)\n",
    "        pickle_file(save_path, \"decoded_cover.pckl\", decoded_C)\n",
    "        pickle_file(save_path, \"secret1_diff.pckl\", diff_S1)\n",
    "        pickle_file(save_path, \"cover_diff.pckl\", diff_C)\n",
    "        pickle_file(save_path, \"secret1_pixel_error.pckl\", S1_error)\n",
    "        pickle_file(save_path, \"cover_pixel_error.pckl\", C_error)\n",
    "\n",
    "        print(f\"Model Saved at: {save_path}\")\n",
    "\n",
    "        print(\"Error per pixel - distance from original RGB\")\n",
    "        print(f\"S1 Pixel Error: {S1_error}\")\n",
    "        print(f\"C Pixel Error: {C_error}\")\n",
    "\n",
    "    actives = [\"relu\", \"selu\", \"gelu\", \"swish\"]\n",
    "    betas = [0.25, 0.5, 0.75, 1.0]\n",
    "    beta = betas[0]\n",
    "    with graph.as_default():\n",
    "        train_model(epochs=1000, activation_function=actives[0], batch_size=32, filters=(50, 20, 10), _beta=beta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}