{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from TinyDataset import TinyImageDataset\n",
    "from StegModels import CNNModels\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "\n",
    "def pickle_file(path, filename, data):\n",
    "    with open(path + filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "train_path = os.path.join(\"datasets/tiny-imagenet-200/\", \"train\")\n",
    "\n",
    "with tf.device('gpu:0'):\n",
    "\n",
    "    def rev_loss(s_true, s_pred):\n",
    "        return beta * K.sum(K.square(s_true - s_pred))\n",
    "\n",
    "\n",
    "    def cover_loss(c_true, c_pred):\n",
    "        return K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "\n",
    "    def full_loss(y_true, y_pred):\n",
    "        # 1 Secret\n",
    "        s_true, c_true = y_true[..., 0:3], y_true[..., 3:6]\n",
    "        s_pred, c_pred = y_pred[..., 0:3], y_pred[..., 3:6]\n",
    "\n",
    "        s_loss = rev_loss(s_true, s_pred)\n",
    "        c_loss = K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "        return sum([s_loss, c_loss])\n",
    "\n",
    "\n",
    "    def full_loss2(y_true, y_pred):\n",
    "        # 2 Secret\n",
    "        s1_true, s2_true, c_true = y_true[..., 0:3], y_true[..., 3:6], y_true[..., 6:9]\n",
    "        s1_pred, s2_pred, c_pred = y_pred[..., 0:3], y_pred[..., 3:6], y_pred[..., 6:9]\n",
    "\n",
    "        s1_loss = rev_loss(s1_true, s1_pred)\n",
    "        s2_loss = rev_loss(s2_true, s2_pred)\n",
    "        c_loss = K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "        return sum([s1_loss, s2_loss, c_loss])\n",
    "\n",
    "\n",
    "    def full_loss3(y_true, y_pred):\n",
    "        # 3 Secrets\n",
    "        s1_true, s2_true, s3_true, c_true = y_true[..., 0:3], y_true[..., 3:6], y_true[..., 6:9], y_true[..., 9:12]\n",
    "        s1_pred, s2_pred, s3_pred, c_pred = y_pred[..., 0:3], y_pred[..., 3:6], y_pred[..., 6:9], y_pred[..., 9:12]\n",
    "\n",
    "        s1_loss = rev_loss(s1_true, s1_pred)\n",
    "        s2_loss = rev_loss(s2_true, s2_pred)\n",
    "        s3_loss = rev_loss(s3_true, s3_pred)\n",
    "        c_loss = K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "        return sum([s1_loss, c_loss, s2_loss, s3_loss])\n",
    "\n",
    "\n",
    "    def full_loss4(y_true, y_pred):\n",
    "        # 3 Secrets\n",
    "        s1_true, s2_true, s3_true, s4_true, c_true = y_true[..., 0:3], \\\n",
    "                                                     y_true[..., 3:6], \\\n",
    "                                                     y_true[..., 6:9], \\\n",
    "                                                     y_true[..., 9:12], \\\n",
    "                                                     y_true[..., 12:15]\n",
    "\n",
    "        s1_pred, s2_pred, s3_pred, s4_pred, c_pred = y_pred[..., 0:3], \\\n",
    "                                                     y_pred[..., 3:6], \\\n",
    "                                                     y_pred[..., 6:9], \\\n",
    "                                                     y_pred[..., 9:12], \\\n",
    "                                                     y_pred[..., 12:15]\n",
    "\n",
    "        s1_loss = rev_loss(s1_true, s1_pred)\n",
    "        s2_loss = rev_loss(s2_true, s2_pred)\n",
    "        s3_loss = rev_loss(s3_true, s3_pred)\n",
    "        s4_loss = rev_loss(s4_true, s4_pred)\n",
    "        c_loss = K.sum(K.square(c_true - c_pred))\n",
    "\n",
    "        return sum([s1_loss, s2_loss, s3_loss, s4_loss, c_loss])\n",
    "\n",
    "\n",
    "    def process(_batch_size, _epochs, save_path, save_interval, activation, filter1, filter2, filter3, verbose,\n",
    "                _sec1_input, _sec2_input, _sec3_input, _cov_input):\n",
    "\n",
    "        cnn_model = CNNModels()\n",
    "        input_shape = _sec1_input.shape[1:]\n",
    "\n",
    "        start_time = time.time()\n",
    "        _encoder_model, _decoder1_model, _decoder2_model, _decoder3_model, _autoencoder_model = \\\n",
    "            cnn_model.train_three_secret_65_filters(\n",
    "                batch_size=_batch_size,\n",
    "                epochs=_epochs,\n",
    "                path=save_path,\n",
    "                shape=input_shape,\n",
    "                rev_loss=rev_loss,\n",
    "                full_loss=full_loss3,\n",
    "                secret1_input=_sec1_input,\n",
    "                secret2_input=_sec2_input,\n",
    "                secret3_input=_sec3_input,\n",
    "                cover_input=_cov_input,\n",
    "                verbose=verbose,\n",
    "                save_interval=save_interval,\n",
    "                activation=activation,\n",
    "                filter1=filter1,\n",
    "                filter2=filter2,\n",
    "                filter3=filter3\n",
    "            )\n",
    "        end_time = round(time.time() - start_time)\n",
    "\n",
    "        if end_time > 60:\n",
    "            end_time = end_time / 60\n",
    "            print(f\"Model Finished Training in: {end_time} m\")\n",
    "        else:\n",
    "            print(f\"Model Finished Training in: {end_time} s\")\n",
    "\n",
    "        return _encoder_model, _decoder1_model, _decoder2_model, _decoder3_model, _autoencoder_model\n",
    "\n",
    "\n",
    "    def train_model(epochs, activation_function, batch_size, filters, _beta):\n",
    "        total_filters = sum(list(filters))\n",
    "        f1 = filters[0]\n",
    "        f2 = filters[1]\n",
    "        f3 = filters[2]\n",
    "\n",
    "        save_path = f\"model-data/50x12x6x{total_filters}F_{batch_size}BS_{epochs}EP_{activation_function}_BETA{beta}/\"\n",
    "        dataset_local = TinyImageDataset(path=train_path, num_classes=25, normalize=True)\n",
    "        X_train_local = dataset_local.load_data()\n",
    "\n",
    "        sec1_input_local = X_train_local[0:1250]\n",
    "        sec2_input_local = X_train_local[1250:2500]\n",
    "        sec3_input_local = X_train_local[2500:3750]\n",
    "        cov_input_local = X_train_local[3750:5000]\n",
    "\n",
    "        encoder_model, decoder1_model, decoder2_model, decoder3_model, autoencoder_model = process(\n",
    "            _batch_size=batch_size,\n",
    "            _epochs=epochs,\n",
    "            save_path=save_path,\n",
    "            save_interval=1,\n",
    "            activation=activation_function,\n",
    "            filter1=f1,\n",
    "            filter2=f2,\n",
    "            filter3=f3,\n",
    "            verbose=1,\n",
    "            _sec1_input=sec1_input_local,\n",
    "            _sec2_input=sec2_input_local,\n",
    "            _sec3_input=sec3_input_local,\n",
    "            _cov_input=cov_input_local\n",
    "        )\n",
    "\n",
    "        def run_loss_history():\n",
    "            with open(save_path + \"loss_history.pckl\", \"rb\") as f:\n",
    "                loss_history = pickle.load(f)\n",
    "\n",
    "            plt.plot(loss_history)\n",
    "            plt.title(f'Loss Curve For: 3X: {total_filters}F_{batch_size}BS_{epochs}EP_{activation_function}_{_beta}')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "\n",
    "            epoch_patch = mpatches.Patch(color='blue', label=f'Total Epochs: {epochs}')\n",
    "            beta_patch = mpatches.Patch(color='blue', label=f'Total Epochs: {_beta}')\n",
    "            batch_patch = mpatches.Patch(color='blue', label=f'Batch Size: {batch_size}')\n",
    "            act_patch = mpatches.Patch(color='blue', label=f'Activation Function: {activation_function}')\n",
    "            plt.legend(handles=[beta_patch, epoch_patch, batch_patch, act_patch], loc=\"upper right\")\n",
    "\n",
    "            plt.savefig(f\"{save_path}loss.png\")\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "\n",
    "        run_loss_history()\n",
    "\n",
    "        decoded = autoencoder_model.predict([sec1_input_local, sec2_input_local, sec3_input_local, cov_input_local])\n",
    "        decoded_S1, decoded_S2, decoded_S3, decoded_C = decoded[..., 0:3], decoded[..., 3:6], decoded[...,\n",
    "                                                                                              6:9], decoded[..., 9:12]\n",
    "\n",
    "        def pixel_errors(input_S1, input_S2, input_S3, input_C, decoded_S1, decoded_S2, decoded_S3, decoded_C):\n",
    "            see_S1pixel = np.sqrt(np.mean(np.square(255 * (input_S1 - decoded_S1))))\n",
    "            see_S2pixel = np.sqrt(np.mean(np.square(255 * (input_S2 - decoded_S2))))\n",
    "            see_S3pixel = np.sqrt(np.mean(np.square(255 * (input_S3 - decoded_S3))))\n",
    "            see_Cpixel = np.sqrt(np.mean(np.square(255 * (input_C - decoded_C))))\n",
    "            return see_S1pixel, see_S2pixel, see_S3pixel, see_Cpixel\n",
    "\n",
    "        S1_error, S2_error, S3_error, C_error = pixel_errors(\n",
    "            sec1_input_local, sec2_input_local, sec3_input_local,\n",
    "            cov_input_local, decoded_S1, decoded_S2, decoded_S3, decoded_C)\n",
    "\n",
    "        diff_S1, diff_S2, diff_S3, diff_C = np.abs(decoded_S1 - sec1_input_local), np.abs(\n",
    "            decoded_S2 - sec3_input_local), \\\n",
    "                                            np.abs(decoded_S3 - sec3_input_local), np.abs(decoded_C - cov_input_local)\n",
    "\n",
    "        def show_image_results():\n",
    "            num_imgs = 8\n",
    "            random_index = [random.randint(0, 375) for _ in range(num_imgs)]\n",
    "            plt.figure(figsize=(11, 12))\n",
    "\n",
    "            def show_image(img, n_rows, num_col, index, first_row=False, title=None):\n",
    "                ax = plt.subplot(n_rows, num_col, index)\n",
    "                plt.imshow(img)\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "                if first_row:\n",
    "                    plt.title(title)\n",
    "\n",
    "            for i, idx in enumerate(random_index):\n",
    "                n_col = 8\n",
    "\n",
    "                show_image(cov_input_local[idx], num_imgs, n_col, i * n_col + 1, first_row=i == 0, title='Cover')\n",
    "\n",
    "                show_image(sec1_input_local[idx], num_imgs, n_col, i * n_col + 2, first_row=i == 0, title='Secret1')\n",
    "                show_image(sec2_input_local[idx], num_imgs, n_col, i * n_col + 3, first_row=i == 0, title='Secret2')\n",
    "                show_image(sec3_input_local[idx], num_imgs, n_col, i * n_col + 4, first_row=i == 0, title='Secret3')\n",
    "\n",
    "                show_image(decoded_C[idx], num_imgs, n_col, i * n_col + 5, first_row=i == 0, title='Cover*')\n",
    "\n",
    "                show_image(decoded_S1[idx], num_imgs, n_col, i * n_col + 6, first_row=i == 0, title='Decoded1')\n",
    "                show_image(decoded_S2[idx], num_imgs, n_col, i * n_col + 7, first_row=i == 0, title='Decoded2')\n",
    "                show_image(decoded_S3[idx], num_imgs, n_col, i * n_col + 8, first_row=i == 0, title='Decoded3')\n",
    "\n",
    "            plt.savefig(f\"{save_path}image_comparison.png\")\n",
    "            plt.figure().clear()\n",
    "            plt.close()\n",
    "\n",
    "        show_image_results()\n",
    "\n",
    "        pickle_file(save_path, \"decoded_secret1.pckl\", decoded_S1)\n",
    "        pickle_file(save_path, \"decoded_secret2.pckl\", decoded_S2)\n",
    "        pickle_file(save_path, \"decoded_secret3.pckl\", decoded_S3)\n",
    "        pickle_file(save_path, \"decoded_cover.pckl\", decoded_C)\n",
    "        pickle_file(save_path, \"secret1_diff.pckl\", diff_S1)\n",
    "        pickle_file(save_path, \"secret2_diff.pckl\", diff_S2)\n",
    "        pickle_file(save_path, \"secret3_diff.pckl\", diff_S3)\n",
    "        pickle_file(save_path, \"cover_diff.pckl\", diff_C)\n",
    "        pickle_file(save_path, \"secret1_pixel_error.pckl\", S1_error)\n",
    "        pickle_file(save_path, \"secret2_pixel_error.pckl\", S2_error)\n",
    "        pickle_file(save_path, \"secret3_pixel_error.pckl\", S3_error)\n",
    "        pickle_file(save_path, \"cover_pixel_error.pckl\", C_error)\n",
    "\n",
    "        print(f\"Model Saved at: {save_path}\")\n",
    "\n",
    "        print(\"Error per pixel - distance from original RGB\")\n",
    "        print(f\"S1 Pixel Error: {S1_error}\")\n",
    "        print(f\"S2 Pixel Error: {S2_error}\")\n",
    "        print(f\"S3 Pixel Error: {S3_error}\")\n",
    "        print(f\"C Pixel Error: {C_error}\")\n",
    "\n",
    "\n",
    "    actives = [\"relu\", \"selu\", \"gelu\", \"swish\"]\n",
    "    betas = [0.25, 0.5, 0.75, 1.0]\n",
    "    beta = betas[0]\n",
    "    with graph.as_default():\n",
    "        train_model(epochs=1, activation_function=actives[1], batch_size=64, filters=(1, 1, 1), _beta= beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}